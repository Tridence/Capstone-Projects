{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Sales Forecasting using Walmart data set.\r\n",
    "\r\n",
    "<img width=\"1300\" height=\"400\" align=\"left\" src=\"https://miro.medium.com/max/2760/1*gsUixexI9DsFfKsS-ZZqng.png\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### General Setup\n",
    "___"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Dataframes.\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Numerical arrays.\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# Stationarity\r\n",
    "from statsmodels.tsa.stattools import adfuller\r\n",
    "\r\n",
    "# Predictions\r\n",
    "from pmdarima.arima import auto_arima\r\n",
    "from statsmodels.tsa.arima.model import ARIMA\r\n",
    "from statsmodels.graphics.tsaplots import plot_acf\r\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from pmdarima.arima.utils import ndiffs\r\n",
    "from pmdarima.utils import diff_inv\r\n",
    "import warnings\r\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\r\n",
    "from statsmodels.tsa.seasonal import STL\r\n",
    "\r\n",
    "# Plotting.\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.dates as mdates\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Change style and size of plots\r\n",
    "plt.style.use(\"ggplot\")\r\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\r\n",
    "plt.rcParams[\"figure.titlesize\"] = 15"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### Exploratory Data Analysis.\n",
    "___\n",
    "\n",
    "The data set consists of 4 csv files: stores, train, test, features. [3] First, I will analyse them separately. [4]\n",
    "\n",
    "> [3] [Walmart Recruiting - Store Sales Forecasting: Data Description](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/data)\n",
    "<br>\n",
    "[4] [Exploratory Data Analysis(EDA): Python](https://towardsdatascience.com/exploratory-data-analysis-eda-python-87178e35b14)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Stores.\n",
    "\n",
    "_1. Load the file._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Load the stores.csv without an index.\r\n",
    "stores = pd.read_csv(\"Walmart Data Set/stores.csv\", header=0)\r\n",
    "\r\n",
    "# Display the dafaframe\r\n",
    "stores.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Store Type    Size      Store A      Store B      Store C\n",
       "0      1    A  151315  219622.0000  140167.0000  42988.00000\n",
       "1      2    A  202307   39690.0000   34875.0000  39690.00000\n",
       "2      4    A  205863  177247.7273  101190.7059  40541.66667\n",
       "3      6    A  202505          NaN          NaN          NaN\n",
       "4      8    A  155078          NaN          NaN          NaN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Store A</th>\n",
       "      <th>Store B</th>\n",
       "      <th>Store C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>219622.0000</td>\n",
       "      <td>140167.0000</td>\n",
       "      <td>42988.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>202307</td>\n",
       "      <td>39690.0000</td>\n",
       "      <td>34875.0000</td>\n",
       "      <td>39690.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "      <td>177247.7273</td>\n",
       "      <td>101190.7059</td>\n",
       "      <td>40541.66667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>202505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>A</td>\n",
       "      <td>155078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Display the dafaframe\r\n",
    "stores.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Store Type   Size  Store A  Store B  Store C\n",
       "40     37    C  39910      NaN      NaN      NaN\n",
       "41     38    C  39690      NaN      NaN      NaN\n",
       "42     42    C  39690      NaN      NaN      NaN\n",
       "43     43    C  41062      NaN      NaN      NaN\n",
       "44     44    C  39910      NaN      NaN      NaN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Store A</th>\n",
       "      <th>Store B</th>\n",
       "      <th>Store C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>37</td>\n",
       "      <td>C</td>\n",
       "      <td>39910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>38</td>\n",
       "      <td>C</td>\n",
       "      <td>39690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>C</td>\n",
       "      <td>39690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>C</td>\n",
       "      <td>41062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>C</td>\n",
       "      <td>39910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "stores.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Store           Size        Store A        Store B       Store C\n",
       "count  45.000000      45.000000       3.000000       3.000000      3.000000\n",
       "mean   23.000000  130287.600000  145519.909100   92077.568633  41073.222223\n",
       "std    13.133926   63825.271991   94068.443124   53234.277201   1712.049789\n",
       "min     1.000000   34875.000000   39690.000000   34875.000000  39690.000000\n",
       "25%    12.000000   70713.000000  108468.863650   68032.852950  40115.833335\n",
       "50%    23.000000  126512.000000  177247.727300  101190.705900  40541.666670\n",
       "75%    34.000000  202307.000000  198434.863650  120678.852950  41764.833335\n",
       "max    45.000000  219622.000000  219622.000000  140167.000000  42988.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Size</th>\n",
       "      <th>Store A</th>\n",
       "      <th>Store B</th>\n",
       "      <th>Store C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>130287.600000</td>\n",
       "      <td>145519.909100</td>\n",
       "      <td>92077.568633</td>\n",
       "      <td>41073.222223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.133926</td>\n",
       "      <td>63825.271991</td>\n",
       "      <td>94068.443124</td>\n",
       "      <td>53234.277201</td>\n",
       "      <td>1712.049789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>34875.000000</td>\n",
       "      <td>39690.000000</td>\n",
       "      <td>34875.000000</td>\n",
       "      <td>39690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>70713.000000</td>\n",
       "      <td>108468.863650</td>\n",
       "      <td>68032.852950</td>\n",
       "      <td>40115.833335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>126512.000000</td>\n",
       "      <td>177247.727300</td>\n",
       "      <td>101190.705900</td>\n",
       "      <td>40541.666670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>202307.000000</td>\n",
       "      <td>198434.863650</td>\n",
       "      <td>120678.852950</td>\n",
       "      <td>41764.833335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>219622.000000</td>\n",
       "      <td>219622.000000</td>\n",
       "      <td>140167.000000</td>\n",
       "      <td>42988.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The stores file consist of information about 45 stores, including the type and size of each. We can observe that there are mainly empty values in the columns Store A, Store B and Store C. \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "<br>\r\n",
    "\r\n",
    "_2. Data cleaning._\r\n",
    "\r\n",
    "The first step to cleansing the data is by checking it for empty values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Check for empty values.\r\n",
    "stores.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Store       0\n",
       "Type        0\n",
       "Size        0\n",
       "Store A    42\n",
       "Store B    42\n",
       "Store C    42\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above confirms that only the last three columns have the empty values. Since they do not provide enough information that could be valuable in the sales forecasting, they will be removed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Remove columns with empty values.\r\n",
    "cleaned_stores = stores.drop(['Store A','Store B','Store C'], axis=1)\r\n",
    "\r\n",
    "# Check for empty values again.\r\n",
    "cleaned_stores.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Store    0\n",
       "Type     0\n",
       "Size     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Calculate maximum values of each store type and set as pie sizes\r\n",
    "sizes = cleaned_stores.groupby('Type').max().Size.values\r\n",
    "labels = cleaned_stores.groupby('Type').max().index\r\n",
    "\r\n",
    "# Create a figure and axis, set a title.\r\n",
    "fig, ax = plt.subplots(figsize=(5,5))\r\n",
    "fig.suptitle(\"Store Size per Type\")\r\n",
    "\r\n",
    "# Build a pie plot.\r\n",
    "ax.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, startangle=140)\r\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle.\r\n",
    "ax.axis('equal') \r\n",
    "\r\n",
    "# Show the plot.\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cleaned_stores' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-06b6fd6b567a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculate maximum values of each store type and set as pie sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaned_stores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Type'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaned_stores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Type'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Create a figure and axis, set a title.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_stores' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "#### Train.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Load the train.csv without an index.\r\n",
    "train = pd.read_csv(\"Walmart Data Set/train.csv\", header=0, parse_dates=True, index_col=\"Date\")\r\n",
    "\r\n",
    "# Display the dafaframe.\r\n",
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Store  Dept  Weekly_Sales  IsHoliday\n",
       "Date                                            \n",
       "2010-02-05      1     1      24924.50      False\n",
       "2010-02-12      1     1      46039.49       True\n",
       "2010-02-19      1     1      41595.55      False\n",
       "2010-02-26      1     1      19403.54      False\n",
       "2010-03-05      1     1      21827.90      False"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-05</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Display the dafaframe.\r\n",
    "train.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Store  Dept  Weekly_Sales  IsHoliday\n",
       "Date                                            \n",
       "2012-09-28     45    98        508.37      False\n",
       "2012-10-05     45    98        628.10      False\n",
       "2012-10-12     45    98       1061.02      False\n",
       "2012-10-19     45    98        760.01      False\n",
       "2012-10-26     45    98       1076.80      False"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>508.37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-05</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>628.10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-12</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>1061.02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-19</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>760.01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-26</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>1076.80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Store           Dept   Weekly_Sales\n",
       "count  421570.000000  421570.000000  421570.000000\n",
       "mean       22.200546      44.260317   15981.258123\n",
       "std        12.785297      30.492054   22711.183519\n",
       "min         1.000000       1.000000   -4988.940000\n",
       "25%        11.000000      18.000000    2079.650000\n",
       "50%        22.000000      37.000000    7612.030000\n",
       "75%        33.000000      74.000000   20205.852500\n",
       "max        45.000000      99.000000  693099.360000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>421570.000000</td>\n",
       "      <td>421570.000000</td>\n",
       "      <td>421570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.200546</td>\n",
       "      <td>44.260317</td>\n",
       "      <td>15981.258123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.785297</td>\n",
       "      <td>30.492054</td>\n",
       "      <td>22711.183519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4988.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2079.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>7612.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>20205.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>693099.360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above dataframe contains weekly sales for 45 stores per department for the period from 2010-02-05 to 2012-10-26. We can see that altogether there are 99 departments. It also includes the department number and whether the week is a special holiday week."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Check for empty values.\r\n",
    "train.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Store           0\n",
       "Dept            0\n",
       "Weekly_Sales    0\n",
       "IsHoliday       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataframe doesn't have any empty values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "depts = train.groupby(\"Store\").Dept.nunique()\r\n",
    "print(f\"Maximum Departments: {np.max(depts)}\\nMinimum Departments: {np.min(depts)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Maximum Departments: 79\n",
      "Minimum Departments: 61\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is clear that the stores have different distribution of departments."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Plot the data by year\r\n",
    "g = sns.catplot(x='IsHoliday', y='Weekly_Sales', data=train)\r\n",
    "g.fig.set_size_inches(10,8)\r\n",
    "\r\n",
    "# Show the plot.\r\n",
    "plt.title(\"Weekly Sales vs Holiday\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "#### Features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the features.csv without an index.\r\n",
    "features = pd.read_csv(\"Walmart Data Set/features.csv\", header=0, parse_dates=True, index_col=\"Date\")\r\n",
    "\r\n",
    "# Display the dafaframe\r\n",
    "features.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Display the dafaframe\r\n",
    "features.tail()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The features file contains additional data related to the store, department, and regional activity for the given dates. MarkDown columns are related to promotional markdowns that Walmart is running. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check for empty values.\r\n",
    "features.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features.loc['2011-11-1': '2011-11-30']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that MarkDowns appear from 11.11.2011."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features = features.loc['2011-11-11': '2013-07-26']\r\n",
    "features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def date_format(ax, int):\r\n",
    "    # Make the x axis display well.\r\n",
    "    weeks = mdates.DayLocator(int)\r\n",
    "    h_fmt = mdates.DateFormatter('%d-%m-%Y')\r\n",
    "\r\n",
    "    # Tick ax axis.\r\n",
    "    ax.xaxis.set_major_locator(weeks)\r\n",
    "    ax.xaxis.set_major_formatter(h_fmt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate mean of columns in features.\r\n",
    "temp = features[features[\"Store\"]==1].groupby([\"Date\"]).mean()\r\n",
    "\r\n",
    "# Create a figure and a set of axis\r\n",
    "fig, [[ax1,ax2],[ax3,ax4]] = plt.subplots(2,2, figsize=(15,12))\r\n",
    "\r\n",
    "# Date Format.\r\n",
    "fig.autofmt_xdate()\r\n",
    "\r\n",
    "# Plot the data.\r\n",
    "ax1.plot(temp.MarkDown1)\r\n",
    "ax1.title.set_text(\"MarkDown 1\")\r\n",
    "ax2.plot(temp.MarkDown2)\r\n",
    "ax2.title.set_text(\"MarkDown 2\")\r\n",
    "ax3.plot(temp.MarkDown3)\r\n",
    "ax3.title.set_text(\"MarkDown 3\")\r\n",
    "ax4.plot(temp.MarkDown4)\r\n",
    "ax4.title.set_text(\"MarkDown 4\")\r\n",
    "\r\n",
    "# Show the plots.\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fill the missing values.\r\n",
    "features[\"MarkDown1\"].fillna(method=\"ffill\", inplace=True)\r\n",
    "features[\"MarkDown2\"].fillna(method=\"ffill\", inplace=True)\r\n",
    "features[\"MarkDown3\"].fillna(method=\"bfill\", inplace=True)\r\n",
    "features[\"MarkDown4\"].fillna(method=\"ffill\", inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a figure and a set of axis\r\n",
    "fig, [ax1,ax2] = plt.subplots(1,2)\r\n",
    "\r\n",
    "# Date Format.\r\n",
    "fig.autofmt_xdate()\r\n",
    "\r\n",
    "# Plot the data.\r\n",
    "ax1.plot(temp.CPI)\r\n",
    "ax1.title.set_text(\"CPI\")\r\n",
    "ax2.plot(temp.Unemployment)\r\n",
    "ax1.title.set_text(\"Unemployment\")\r\n",
    "\r\n",
    "# Show the plots.\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filling missing values for CPI and unemployment\r\n",
    "features[\"CPI\"].fillna(method=\"ffill\", inplace=True)\r\n",
    "features[\"Unemployment\"].fillna(method=\"ffill\", inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checking for missing values again.\r\n",
    "features.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Separate test features from train.\r\n",
    "features_train = features.loc['2011-11-11': '2012-10-26'].reset_index()\r\n",
    "features_test = features.loc['2012-11-02': '2013-07-26'].reset_index()\r\n",
    "features_train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\r\n",
    "\r\n",
    "### Mergining data sets.\r\n",
    "___"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Merge the dataframes into one.\r\n",
    "df = train.merge(features_train, on=['Store', 'IsHoliday', 'Date'],how='left').dropna()\r\n",
    "df = df.merge(cleaned_stores, on=['Store'], how='left')\r\n",
    "\r\n",
    "# Timedelta\r\n",
    "#df['Date'] = df['Date'] + pd.to_timedelta(df.groupby('Date').cumcount(), unit='m')\r\n",
    "df=df.set_index(['Date'])\r\n",
    "\r\n",
    "# Display the new dataframe with a date index.\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-03eca8aa0c97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Merge the dataframes into one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Store'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'IsHoliday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_stores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Store'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Timedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.index.duplicated().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a figure and axis.\r\n",
    "fig, ax = plt.subplots(figsize=(13,10))\r\n",
    "fig.suptitle(\"Weekly Sales\")\r\n",
    "\r\n",
    "# Date formatter.\r\n",
    "date_format(ax,10)\r\n",
    "fig.autofmt_xdate()\r\n",
    "\r\n",
    "# Plot the sales\r\n",
    "sns.scatterplot(data=df, x=df.index, y=\"Weekly_Sales\", ax=ax)\r\n",
    "\r\n",
    "# Show the plot.\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a figure and axis.\r\n",
    "fig, ax = plt.subplots(figsize=(13,10))\r\n",
    "fig.suptitle(\"Correlation Map\")\r\n",
    "\r\n",
    "# Plot the correlation\r\n",
    "corr = df.corr()\r\n",
    "cmap = sns.diverging_palette(100, 275, as_cmap=True)\r\n",
    "sns.heatmap(corr, cmap=cmap, center=0, annot=True,square=True,cbar_kws={\"shrink\": .7}, ax=ax)\r\n",
    "\r\n",
    "# Set a title and rotate x axis \r\n",
    "plt.xticks(rotation=45)\r\n",
    "plt.tight_layout()\r\n",
    "\r\n",
    "# Show the plot.\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The heatmap shows that weekly sales are dependent on:\r\n",
    "* Store Size\r\n",
    "* Department\r\n",
    "* MarkDown5, MarkDown1, MarkDown3, MarkDown4, MarkDown2\r\n",
    "* IsHoliday"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\r\n",
    "    \r\n",
    "### Holidays & Markdowns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a figure and axis.\r\n",
    "fig, ax = plt.subplots(figsize=(20,8))\r\n",
    "fig.suptitle(\"Weekly Sales per Store\")\r\n",
    "\r\n",
    "# Plot the data by year\r\n",
    "per_store = df.groupby(\"Store\").agg({\"Weekly_Sales\": \"sum\"})\r\n",
    "per_store.sort_values(\"Weekly_Sales\").plot.bar(ax=ax)\r\n",
    "\r\n",
    "# Set a title and change rotation of xticks back to 0 \r\n",
    "plt.title(\"2011-2012\")\r\n",
    "plt.xticks(rotation=0)\r\n",
    "\r\n",
    "# Show the plot.\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "def test_stationarity(ts):\r\n",
    "    # Create a figure and axis.\r\n",
    "    fig, ax = plt.subplots()\r\n",
    "    fig.suptitle('Rolling Mean & Standard Deviation')\r\n",
    "\r\n",
    "    # Date Format.\r\n",
    "    date_format(ax,10)\r\n",
    "    fig.autofmt_xdate()\r\n",
    "\r\n",
    "    # Determing rolling statistics\r\n",
    "    rolmean = ts[\"Weekly_Sales\"].rolling(12).mean()\r\n",
    "    rolstd = ts[\"Weekly_Sales\"].rolling(12).std()\r\n",
    "\r\n",
    "    # Plot rolling statistics:\r\n",
    "    sns.lineplot(data=ts, x=\"Date\", y=\"Weekly_Sales\", ax=ax, label='Original')\r\n",
    "    sns.lineplot(data=ts, x=\"Date\", y=rolmean, ax=ax, label='Rolling Mean')\r\n",
    "    sns.lineplot(data=ts, x=\"Date\", y=rolstd, ax=ax, label = 'Rolling Std')\r\n",
    "\r\n",
    "    # Show the plot\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    #Perform Dickey-Fuller test:\r\n",
    "    print('Results of Dickey-Fuller Test:')\r\n",
    "    dftest = adfuller(ts, autolag='AIC')\r\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\r\n",
    "    for key,value in dftest[4].items():\r\n",
    "        dfoutput[f'Critical Value ({key})'] = value\r\n",
    "    print(dfoutput)\r\n",
    "\r\n",
    "sales_df = pd.DataFrame(df[\"Weekly_Sales\"])\r\n",
    "test_stationarity(sales_df)\r\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Change to pivot table per department and tore\r\n",
    "sales = pd.pivot_table(df,index=df.index,columns=[df.Store, df.Dept], values='Weekly_Sales',aggfunc=np.sum)\r\n",
    "\r\n",
    "# Stack the pivot table and remove rows with more than 10% (apprx 5) missing values\r\n",
    "sales = sales.dropna(thresh=len(sales) - 5, axis=0)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sales = sales.fillna(method=\"bfill\")\r\n",
    "sales = sales.fillna(method=\"ffill\")\r\n",
    "sales.isnull().sum().any()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sales.head()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res = STL(sales.values.flatten(), period=7).fit()\r\n",
    "res.plot()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### ARIMA model.\n",
    "___"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_dept():\r\n",
    "    depts_sales = []\r\n",
    "    for i,j in sales:\r\n",
    "        dept_sales = sales.loc[:, (i, j)]\r\n",
    "        depts_sales.append(dept_sales)\r\n",
    "    return depts_sales"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def split(dept_sales):\r\n",
    "    size = int(len(dept_sales) * 0.7)\r\n",
    "    train, val = dept_sales[0:size], dept_sales[size:]\r\n",
    "    return train, val"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def adf(dept_sales):\r\n",
    "    dftest = adfuller(dept_sales, autolag='AIC')\r\n",
    "    values = []\r\n",
    "    for key,value in dftest[4].items():\r\n",
    "        values.append(value)\r\n",
    "    return dftest[0], values[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_stationary(dept_sales):\r\n",
    "    dept_sales_diff = dept_sales.diff().dropna()\r\n",
    "    return dept_sales_diff"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def inv_diff (df_orig_column,df_diff_column, periods):\r\n",
    "    # Generate np.array for the diff_inv function - it includes first n values(n = \r\n",
    "    # periods) of original data & further diff values of given periods\r\n",
    "    value = np.array(df_orig_column[:periods].tolist()+df_diff_column[periods:].tolist())\r\n",
    "\r\n",
    "    # Generate np.array with inverse diff\r\n",
    "    inv_diff_vals = diff_inv(value, periods,1 )[periods:]\r\n",
    "    return inv_diff_vals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def arima(dept_sales, train, val):\r\n",
    "    # Create a model\r\n",
    "    model = auto_arima(dept_sales, start_p=0, start_q=0, start_P=0, start_Q=0,\r\n",
    "                        test='adf', # use Augmented Dickey-Fuller(adftest) test to find optimal 'd'\r\n",
    "                      trend=\"ct\", stationary=True,\r\n",
    "                      stepwise=False)\r\n",
    "    model.fit(train)\r\n",
    "    preds = model.predict(n_periods=len(val))\r\n",
    "    val_vs_forecast = plot(preds, val)\r\n",
    "    return val_vs_forecast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot(preds, val):\r\n",
    "    forecast_df = pd.DataFrame(preds,index = val.index,columns=['Prediction'])\r\n",
    "    \r\n",
    "    val_vs_forecast = pd.concat([val,forecast_df],axis=1)\r\n",
    "    val_vs_forecast.plot()\r\n",
    "    plt.title(f'RMSE: {rmse(val, forecast_df):.2f}')    \r\n",
    "    return val_vs_forecast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def rmse(val, preds):\r\n",
    "    rmse = np.sqrt(mean_squared_error(val, preds))\r\n",
    "    return rmse"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predictions_per_dept(dept_sales):\r\n",
    "    train, val = split(dept_sales)\r\n",
    "    #test_stat, crit_val = adf(dept_sales)\r\n",
    "    #if test_stat > crit_val:\r\n",
    "    #    dept_sales_diff = make_stationary(dept_sales)\r\n",
    "    #    train_diff, val_diff = split(dept_sales_diff)\r\n",
    "     #   val_vs_forecast = arima(dept_sales_diff, train_diff, val_diff)\r\n",
    "    val_vs_forecast = arima(dept_sales, train, val)\r\n",
    "    return val_vs_forecast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions = pd.DataFrame()\r\n",
    "depts_sales = get_dept()\r\n",
    "predictions = predictions.merge(predictions_per_dept(depts_sales[9]), on=\"Date\", how=\"left\")\r\n",
    "predictions.T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Future forecast\r\n",
    "predictions = pd.DataFrame()\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "depts_sales = get_dept()\r\n",
    "for i in range(0, 3):\r\n",
    "    preds = predictions_per_dept(depts_sales[i])\r\n",
    "    predictions = predictions.append(preds)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fd2951b82103>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a figure and axis.\r\n",
    "fig, ax = plt.subplots()\r\n",
    "\r\n",
    "ax.plot(val, label='Original')\r\n",
    "ax.plot(preds, label='Predicted', color='b')\r\n",
    "\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train, val = split(pd.DataFrame(depts_sales[9]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# evaluate an ARIMA model for a given order (p,d,q)\r\n",
    "def evaluate_arima_model(order):\r\n",
    "    # prepare training dataset\r\n",
    "    model = ARIMA(train, order=order).fit()\r\n",
    "    predictions = model.predict(start=1, end=len(val), typ='levels')\r\n",
    "    # calculate out of sample error\r\n",
    "    rmse = np.sqrt(mean_squared_error(val, predictions))\r\n",
    "    return rmse"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# evaluate combinations of p, d and q values for an ARIMA model\r\n",
    "def evaluate_models(p_values, d_values, q_values):\r\n",
    "    best_score, best_cfg = float(\"inf\"), None\r\n",
    "    for p in p_values:\r\n",
    "        for d in d_values:\r\n",
    "            for q in q_values:\r\n",
    "                order = (p,d,q)\r\n",
    "                rmse = evaluate_arima_model(order)\r\n",
    "                if rmse < best_score:\r\n",
    "                    best_score, best_cfg = rmse, order\r\n",
    "    print(f'Best ARIMA {best_cfg}: RMSE={best_score:.3f}')\r\n",
    "\r\n",
    "# evaluate parameters\r\n",
    "p_values = [0, 1, 2, 4, 6, 8, 10]\r\n",
    "d_values = range(0, 3)\r\n",
    "q_values = range(0, 3)\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "evaluate_models(p_values, d_values, q_values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the train.csv without an index.\r\n",
    "test_data = pd.read_csv(\"Walmart Data Set/test.csv\", header=0, parse_dates=True, index_col=\"Date\")\r\n",
    "\r\n",
    "# Display the dafaframe.\r\n",
    "test_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_data.tail()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_df = test_data.merge(features_test, on=['Store', 'IsHoliday', 'Date'],how='left')\r\n",
    "test_df.index = test_df.Date\r\n",
    "test_df = test_df.drop(\"Date\", axis=1)\r\n",
    "test_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_df.tail()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_df.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### References \r\n",
    "\r\n",
    "> 1.[How to group pandas DataFrame entries by date in a non-unique column](https://stackoverflow.com/questions/11391969/how-to-group-pandas-dataframe-entries-by-date-in-a-non-unique-column)<br>\r\n",
    "2. [Date tick labels](https://matplotlib.org/3.1.1/gallery/text_labels_and_annotations/date.html)<br>\r\n",
    "3. [Pandas Groupby: Summarising, Aggregating, and Grouping data in Python](https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/#multiple-statistics-per-group)<br>\r\n",
    "4. [Augmented Dickey-Fuller Test in Python](http://www.hackdeploy.com/augmented-dickey-fuller-test-in-python/)<br>\r\n",
    "5. [A comprehensive beginners guide to create a Time Series Forecast (with Codes in Python and R)](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/)<br>\r\n",
    "6. [Using Python and Auto ARIMA to Forecast Seasonal Time Series](https://medium.com/@josemarcialportilla/using-python-and-auto-arima-to-forecast-seasonal-time-series-90877adff03c)<br>\r\n",
    "7. [python pandas : split a data frame based on a column value](https://stackoverflow.com/questions/36192633/python-pandas-split-a-data-frame-based-on-a-column-value)<br>\r\n",
    "8. [How should I Handle duplicate times in time series data with pandas?](https://stackoverflow.com/questions/44128600/how-should-i-handle-duplicate-times-in-time-series-data-with-pandas)\r\n",
    "9. [pandas dataframe select columns in multiindex [duplicate]](https://stackoverflow.com/questions/25189575/pandas-dataframe-select-columns-in-multiindex)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "97bb76a2fae8145d19ad2c471a2a232d311c2936641c752e89122f5680927a7c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}